{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To save file size, I cleared all the output. You could redo these inputs to see the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import time \n",
    "from sklearn.datasets import load_svmlight_file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_svmlight_file(\"housing_scale.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X,y = data[0],data[1]\n",
    "X = X.toarray()\n",
    "y = y.reshape((len(y),1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_val,y_train,y_val = train_test_split(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(str(len(X_train))+' '+str(len(X_val)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#implement a base class of Linear Regression Model\n",
    "class LinearRegression(object):\n",
    "    def __init__(self):\n",
    "        self.W = 0\n",
    "        self.lamda = 0.0\n",
    "        \n",
    "    \n",
    "    def initialPar(self,shape,method='default'):\n",
    "        '''\n",
    "        shape: the shape of par W\n",
    "        mathod: the initial method of par W\n",
    "        '''\n",
    "        if method == 'default':\n",
    "            #add one dimension of b\n",
    "            self.W = np.zeros(shape+1)\n",
    "        elif method == 'random':\n",
    "            self.W = np.random.rand(shape+1)\n",
    "        elif method == 'norm':\n",
    "            self.W = np.random.randn(shape+1)\n",
    "        self.W = self.W.reshape((len(self.W),1))\n",
    "        \n",
    "    def getLoss(self,y_pre,y_ground,method='squared'):\n",
    "        '''\n",
    "        method: the method of get Loss\n",
    "        '''\n",
    "        #self.lamda = lamda\n",
    "        if method == 'absolute':\n",
    "            loss = np.sum(np.fabs(y_pre-y_ground)) / y_pre.shape[0]\n",
    "        elif method == 'squared':\n",
    "            loss = np.sum(np.square(y_pre-y_ground)) /(2* y_pre.shape[0])\n",
    "        sloss = loss + np.sum(np.square(self.W))*self.lamda/2\n",
    "        print('Pure loss: '+str(loss)+'.....Total loss: '+str(sloss))\n",
    "        return sloss\n",
    "        \n",
    "    def train(self,X_train,y_train):\n",
    "        pass\n",
    "    \n",
    "    def predict(self,X_test):\n",
    "        X_test = np.insert(X_test,0,1,axis=1)\n",
    "        y_pre = np.dot(X_test,self.W)\n",
    "        return y_pre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# implement a subclass of Linear Regression Model: Closed-Form Solution\n",
    "class ClosedFormLinearRegression(LinearRegression):\n",
    "    def __init__(self):\n",
    "        super(ClosedFormLinearRegression,self).__init__()\n",
    "        \n",
    "    def train(self,X_train,y_train):\n",
    "        start = time.time()\n",
    "        print('Training...')\n",
    "        X_train = np.insert(X_train,0,1,axis=1)\n",
    "        print(X_train.shape)\n",
    "        w_temp = self.lamda * np.identity(X_train.shape[1]) + np.dot(np.transpose(X_train),X_train)\n",
    "        #w_temp = np.dot(np.transpose(X_train),X_train)\n",
    "        try:\n",
    "            w_temp = np.linalg.inv(w_temp)\n",
    "        except np.linalg.LinAlgError:\n",
    "            print('Singular matrix!!!!!Process interprutted!!!!!')\n",
    "        else:\n",
    "            w_temp = np.dot(w_temp,np.transpose(X_train))\n",
    "            w_temp = np.dot(w_temp,y_train)\n",
    "        self.W = w_temp\n",
    "        print('Training...'+str(time.time()-start)+'s...Successful!!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "closed_losses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cc1 = ClosedFormLinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cc1.initialPar(X_train.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cc1.W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cc1.train(X_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cc1.W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss1 = cc1.getLoss(cc1.predict(X_val),y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "closed_losses.append(loss1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cc2 = ClosedFormLinearRegression()\n",
    "cc2.initialPar(X_train.shape[1])\n",
    "cc2.train(X_train,y_train)\n",
    "loss2 = cc2.getLoss(cc2.predict(X_val),y_val)\n",
    "closed_losses.append(loss2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cc3 = ClosedFormLinearRegression()\n",
    "cc3.initialPar(X_train.shape[1])\n",
    "cc3.train(X_train,y_train)\n",
    "loss3 = cc3.getLoss(cc3.predict(X_val),y_val)\n",
    "closed_losses.append(loss3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cc4 = ClosedFormLinearRegression()\n",
    "cc4.initialPar(X_train.shape[1])\n",
    "cc4.train(X_train,y_train)\n",
    "loss4 = cc4.getLoss(cc4.predict(X_val),y_val)\n",
    "closed_losses.append(loss4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cc5 = ClosedFormLinearRegression()\n",
    "cc5.initialPar(X_train.shape[1])\n",
    "cc5.train(X_train,y_train)\n",
    "loss5 = cc5.getLoss(cc5.predict(X_val),y_val)\n",
    "closed_losses.append(loss5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(1,6),closed_losses)\n",
    "plt.xticks(range(1,6), ('cc1', 'cc2', 'cc3', 'cc4', 'cc5'))\n",
    "plt.xlabel('closed-form models')\n",
    "plt.ylabel('loss')\n",
    "plt.savefig('cf1.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#implement a subclass of Linear Regression Model: Gradient Descent Solution\n",
    "class GradientDescentLinearRegression(LinearRegression):\n",
    "    def __init__(self):\n",
    "        super(GradientDescentLinearRegression,self).__init__()\n",
    "    \n",
    "    def train(self,X_train,y_train,X_val,y_val,maxLoop=5000,epsilon=0.01,rate0 = 0.01):\n",
    "        #f = open(filename,'w')\n",
    "        start = time.time()\n",
    "        print('Training...')\n",
    "        train_losses = []\n",
    "        val_losses = []\n",
    "        X_train = np.insert(X_train,0,1,axis=1)\n",
    "        for i in range(maxLoop):\n",
    "            rate = 1/float(i+1)+ rate0\n",
    "            count = np.random.choice(X_train.shape[0])\n",
    "            #f.write('\\nrandom choice: '+str(count))\n",
    "            x_sample = X_train[count]\n",
    "            y_sample = y_train[count]\n",
    "            x_sample = x_sample.reshape((1,len(x_sample)))\n",
    "            y_sample = y_sample.reshape((1,len(y_sample)))\n",
    "            #f.write('\\nX_sample:'+str(x_sample))\n",
    "            #f.write('\\ny_sample:'+str(y_sample))\n",
    "            #g_temp1 = self.lamda*self.W - np.dot(x_sample.T,y_sample)\n",
    "            #g_temp2 = np.dot(np.dot(x_sample.T,x_sample),self.W)\n",
    "            g_temp0 = np.dot(x_sample,self.W) - y_sample\n",
    "            g_temp1 = np.dot(x_sample.T,g_temp0)\n",
    "            gradient = g_temp1 + self.lamda*self.W\n",
    "            self.W = self.W - rate * gradient\n",
    "            #f.write('gradient: '+str(gradient)+'\\nlearning rate:  '+str(rate))\n",
    "            \n",
    "            \n",
    "            y_train_pre = np.dot(X_train,self.W)\n",
    "            y_val_pre = self.predict(X_val)\n",
    "            y_train_loss = self.getLoss(y_train_pre,y_train)\n",
    "            y_val_loss = self.getLoss(y_val_pre,y_val)\n",
    "            #f.write('\\nepoch '+str(i+1)+'   Training loss:   '+str(y_train_loss)+'  Valing loss:   '+str(y_val_loss)+'\\n\\n')\n",
    "            print('epoch '+str(i+1)+' learning rate:  '+str(rate)+'   Training loss:   '+str(y_train_loss)+'  Valing loss:   '+str(y_val_loss))\n",
    "            train_losses.append(y_train_loss)\n",
    "            val_losses.append(y_val_loss)\n",
    "            #if abs(loss - y_train_loss) > epsilon:\n",
    "            #    loss = y_train_loss\n",
    "            #else:\n",
    "            #    print(str(loss-y_train_loss))\n",
    "            #    print(\"Convergencing...\")\n",
    "            #    break\n",
    "        print('Training...'+str(time.time()-start)+'s...Successful!!')\n",
    "        plt.plot(range(1,len(train_losses)+1),train_losses)\n",
    "        plt.plot(range(1,len(val_losses)+1),val_losses)\n",
    "        return train_losses, val_losses\n",
    "        #f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gg1 = GradientDescentLinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gg1.initialPar(X_train.shape[1],'norm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gg1_train,gg1_val = gg1.train(X_train,y_train,X_val,y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gg2 = GradientDescentLinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gg2.initialPar(X_train.shape[1],'random')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gg2_train,gg2_val = gg2.train(X_train,y_train,X_val,y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gg3 = GradientDescentLinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gg3.initialPar(X_train.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gg3_train,gg3_val = gg3.train(X_train,y_train,X_val,y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gg11 = GradientDescentLinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gg11.initialPar(X_train.shape[1],'norm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gg11_train,gg11_val = gg11.train(X_train,y_train,X_val,y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gg22 = GradientDescentLinearRegression()\n",
    "gg22.initialPar(X_train.shape[1],'random')\n",
    "gg22_train,gg22_val = gg22.train(X_train,y_train,X_val,y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gg33 = GradientDescentLinearRegression()\n",
    "gg33.initialPar(X_train.shape[1])\n",
    "gg33_train,gg33_val = gg33.train(X_train,y_train,X_val,y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(16,6))\n",
    "plt.subplot(1,3,1)\n",
    "plt.plot(range(1,len(gg1_train)+1), gg1_train, 'r--')\n",
    "plt.plot(range(1,len(gg2_train)+1), gg2_train, 'bp-.')\n",
    "label = ['gg1_train', 'gg2_train'] \n",
    "plt.legend(label, loc='upper right')\n",
    "plt.xlabel('iterations')\n",
    "plt.ylabel('loss')\n",
    "plt.subplot(1,3,2)\n",
    "plt.plot(range(1,len(gg2_train)+1), gg2_train, 'b--')\n",
    "plt.plot(range(1,len(gg3_train)+1), gg3_train, 'gp-.')\n",
    "plt.plot(range(1,len(gg22_train)+1), gg22_train, 'c--')\n",
    "plt.plot(range(1,len(gg33_train)+1), gg33_train, 'kp-.')\n",
    "label = ['gg2_train','gg3_train', 'gg22_train','gg33_train'] \n",
    "plt.legend(label, loc='upper right')\n",
    "plt.xlabel('iterations')\n",
    "plt.ylabel('loss')\n",
    "plt.subplot(1,3,3)\n",
    "plt.plot(range(1,len(gg2_train)+1), gg2_train, 'b--')\n",
    "plt.plot(range(1,len(gg3_train)+1), gg3_train, 'gp-.')\n",
    "label = ['gg2_train','gg3_train'] \n",
    "plt.legend(label, loc='upper right')\n",
    "plt.xlabel('iterations')\n",
    "plt.ylabel('loss')\n",
    "plt.tight_layout()\n",
    "#plt.subplots_adjust(wspace =2, hspace =2)\n",
    "plt.savefig('gg3.pdf')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gg4 = GradientDescentLinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gg4.initialPar(X_train.shape[1],'random')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "gg4_train,gg4_val = gg4.train(X_train,y_train,X_val,y_val,rate0=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gg5 = GradientDescentLinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gg5.initialPar(X_train.shape[1],'random')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gg5_train,gg5_val = gg5.train(X_train,y_train,X_val,y_val,rate0=0.1,maxLoop=100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gg6 = GradientDescentLinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gg6.initialPar(X_train.shape[1],'random')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gg6_train,gg6_val = gg6.train(X_train,y_train,X_val,y_val,rate0=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gg7 = GradientDescentLinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gg7.initialPar(X_train.shape[1],'random')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gg7_train,gg7_val = gg7.train(X_train,y_train,X_val,y_val,rate0=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gg8 = GradientDescentLinearRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gg8.initialPar(X_train.shape[1],'random')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gg8_train,gg8_val = gg8.train(X_train,y_train,X_val,y_val,rate0=0.001,maxLoop=100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6,6))\n",
    "plt.subplot(2,2,1)\n",
    "plt.plot(range(1,len(gg4_train)+1), gg4_train, 'r--')\n",
    "plt.plot(range(1,len(gg4_val)+1), gg4_val, 'b--')\n",
    "label = ['gg4_train', 'gg4_val'] \n",
    "plt.legend(label, loc='upper right')\n",
    "plt.xlabel('iterations')\n",
    "plt.ylabel('loss')\n",
    "plt.title('learning rate = 1.0')\n",
    "plt.subplot(2,2,2)\n",
    "plt.plot(range(1,len(gg5_train)+1), gg5_train, 'r--')\n",
    "plt.plot(range(1,len(gg5_val)+1), gg5_val, 'b-.')\n",
    "label = ['gg5_train','gg5_val'] \n",
    "plt.legend(label, loc='upper right')\n",
    "plt.xlabel('iterations')\n",
    "plt.ylabel('loss')\n",
    "plt.title('learning rate = 0.1')\n",
    "plt.subplot(2,2,3)\n",
    "plt.plot(range(1,len(gg6_train)+1), gg6_train, 'r--')\n",
    "plt.plot(range(1,len(gg6_val)+1), gg6_val, 'b--')\n",
    "label = ['gg6_train', 'gg6_val'] \n",
    "plt.legend(label, loc='upper right')\n",
    "plt.xlabel('iterations')\n",
    "plt.ylabel('loss')\n",
    "plt.title('learning rate = 0.01')\n",
    "plt.subplot(2,2,4)\n",
    "plt.plot(range(1,len(gg8_train)+1), gg8_train, 'r--')\n",
    "plt.plot(range(1,len(gg8_val)+1), gg8_val, 'b--')\n",
    "label = ['gg8_train', 'gg8_val'] \n",
    "plt.legend(label, loc='upper right')\n",
    "plt.xlabel('iterations')\n",
    "plt.ylabel('loss')\n",
    "plt.title('learning rate = 0.001')\n",
    "plt.tight_layout()\n",
    "#plt.subplots_adjust(wspace =2, hspace =2)\n",
    "plt.savefig('gg4.pdf')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
